{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data to/from AFS\n",
    "\n",
    "## README\n",
    "\n",
    "Set your AFS_NAME, AFS_KEY and AFS_SHARE envs\n",
    "\n",
    "Specify your \"local_root\" directory where to download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading train-labels-idx1-ubyte.gz [==================================================]\n",
      "Uploading train-images-idx3-ubyte.gz [==================================================]\n",
      "Downloading train-images-idx3-ubyte.gz [==================================================]\n",
      "Downloading train-labels-idx1-ubyte.gz [==================================================]\n"
     ]
    }
   ],
   "source": [
    "from k8scontroller.data_loader import AFSLoader\n",
    "\n",
    "\n",
    "local_root=\"./shared_folder\"\n",
    "data_folder=\"./data\"\n",
    "afs_loader = AFSLoader(local_root=local_root)\n",
    "afs_path = afs_loader.upload_data_afs(data_folder)\n",
    "afs_loader.download_data_afs(afs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'api_version': 'batch/v1',\n",
      " 'kind': 'Job',\n",
      " 'metadata': {'annotations': None,\n",
      "              'cluster_name': None,\n",
      "              'creation_timestamp': datetime.datetime(2019, 5, 7, 14, 6, 29, tzinfo=tzutc()),\n",
      "              'deletion_grace_period_seconds': None,\n",
      "              'deletion_timestamp': None,\n",
      "              'finalizers': None,\n",
      "              'generate_name': None,\n",
      "              'generation': None,\n",
      "              'initializers': None,\n",
      "              'labels': {'controller-uid': '4f6de36c-70d1-11e9-ab6a-0e4c0a4dfd91',\n",
      "                         'job-name': 'pgv4hmq8alm4'},\n",
      "              'name': 'pgv4hmq8alm4',\n",
      "              'namespace': 'default',\n",
      "              'owner_references': None,\n",
      "              'resource_version': '5779018',\n",
      "              'self_link': '/apis/batch/v1/namespaces/default/jobs/pgv4hmq8alm4',\n",
      "              'uid': '4f6de36c-70d1-11e9-ab6a-0e4c0a4dfd91'},\n",
      " 'spec': {'active_deadline_seconds': None,\n",
      "          'backoff_limit': 6,\n",
      "          'completions': 1,\n",
      "          'manual_selector': None,\n",
      "          'parallelism': 1,\n",
      "          'selector': {'match_expressions': None,\n",
      "                       'match_labels': {'controller-uid': '4f6de36c-70d1-11e9-ab6a-0e4c0a4dfd91'}},\n",
      "          'template': {'metadata': {'annotations': None,\n",
      "                                    'cluster_name': None,\n",
      "                                    'creation_timestamp': None,\n",
      "                                    'deletion_grace_period_seconds': None,\n",
      "                                    'deletion_timestamp': None,\n",
      "                                    'finalizers': None,\n",
      "                                    'generate_name': None,\n",
      "                                    'generation': None,\n",
      "                                    'initializers': None,\n",
      "                                    'labels': {'controller-uid': '4f6de36c-70d1-11e9-ab6a-0e4c0a4dfd91',\n",
      "                                               'job-name': 'pgv4hmq8alm4'},\n",
      "                                    'name': None,\n",
      "                                    'namespace': None,\n",
      "                                    'owner_references': None,\n",
      "                                    'resource_version': None,\n",
      "                                    'self_link': None,\n",
      "                                    'uid': None},\n",
      "                       'spec': {'active_deadline_seconds': None,\n",
      "                                'affinity': None,\n",
      "                                'automount_service_account_token': None,\n",
      "                                'containers': [{'args': None,\n",
      "                                                'command': ['/bin/sh',\n",
      "                                                            '-c',\n",
      "                                                            'while :; do echo '\n",
      "                                                            \"'IM HERE'; sleep \"\n",
      "                                                            '1; done'],\n",
      "                                                'env': None,\n",
      "                                                'env_from': None,\n",
      "                                                'image': 'busybox',\n",
      "                                                'image_pull_policy': 'Always',\n",
      "                                                'lifecycle': None,\n",
      "                                                'liveness_probe': None,\n",
      "                                                'name': 'pgv4hmq8alm4',\n",
      "                                                'ports': None,\n",
      "                                                'readiness_probe': None,\n",
      "                                                'resources': {'limits': None,\n",
      "                                                              'requests': None},\n",
      "                                                'security_context': None,\n",
      "                                                'stdin': None,\n",
      "                                                'stdin_once': None,\n",
      "                                                'termination_message_path': '/dev/termination-log',\n",
      "                                                'termination_message_policy': 'File',\n",
      "                                                'tty': None,\n",
      "                                                'volume_devices': None,\n",
      "                                                'volume_mounts': [{'mount_path': '/input',\n",
      "                                                                   'mount_propagation': None,\n",
      "                                                                   'name': 'azure-volume',\n",
      "                                                                   'read_only': None,\n",
      "                                                                   'sub_path': None}],\n",
      "                                                'working_dir': None}],\n",
      "                                'dns_config': None,\n",
      "                                'dns_policy': 'ClusterFirst',\n",
      "                                'host_aliases': None,\n",
      "                                'host_ipc': None,\n",
      "                                'host_network': None,\n",
      "                                'host_pid': None,\n",
      "                                'hostname': None,\n",
      "                                'image_pull_secrets': None,\n",
      "                                'init_containers': None,\n",
      "                                'node_name': None,\n",
      "                                'node_selector': None,\n",
      "                                'priority': None,\n",
      "                                'priority_class_name': None,\n",
      "                                'readiness_gates': None,\n",
      "                                'restart_policy': 'Never',\n",
      "                                'runtime_class_name': None,\n",
      "                                'scheduler_name': 'default-scheduler',\n",
      "                                'security_context': {'fs_group': None,\n",
      "                                                     'run_as_group': None,\n",
      "                                                     'run_as_non_root': None,\n",
      "                                                     'run_as_user': None,\n",
      "                                                     'se_linux_options': None,\n",
      "                                                     'supplemental_groups': None,\n",
      "                                                     'sysctls': None},\n",
      "                                'service_account': None,\n",
      "                                'service_account_name': None,\n",
      "                                'share_process_namespace': None,\n",
      "                                'subdomain': None,\n",
      "                                'termination_grace_period_seconds': 30,\n",
      "                                'tolerations': None,\n",
      "                                'volumes': [{'aws_elastic_block_store': None,\n",
      "                                             'azure_disk': None,\n",
      "                                             'azure_file': {'read_only': None,\n",
      "                                                            'secret_name': 'azure-secret',\n",
      "                                                            'share_name': 'datalake'},\n",
      "                                             'cephfs': None,\n",
      "                                             'cinder': None,\n",
      "                                             'config_map': None,\n",
      "                                             'downward_api': None,\n",
      "                                             'empty_dir': None,\n",
      "                                             'fc': None,\n",
      "                                             'flex_volume': None,\n",
      "                                             'flocker': None,\n",
      "                                             'gce_persistent_disk': None,\n",
      "                                             'git_repo': None,\n",
      "                                             'glusterfs': None,\n",
      "                                             'host_path': None,\n",
      "                                             'iscsi': None,\n",
      "                                             'name': 'azure-volume',\n",
      "                                             'nfs': None,\n",
      "                                             'persistent_volume_claim': None,\n",
      "                                             'photon_persistent_disk': None,\n",
      "                                             'portworx_volume': None,\n",
      "                                             'projected': None,\n",
      "                                             'quobyte': None,\n",
      "                                             'rbd': None,\n",
      "                                             'scale_io': None,\n",
      "                                             'secret': None,\n",
      "                                             'storageos': None,\n",
      "                                             'vsphere_volume': None}]}},\n",
      "          'ttl_seconds_after_finished': None},\n",
      " 'status': {'active': None,\n",
      "            'completion_time': None,\n",
      "            'conditions': None,\n",
      "            'failed': None,\n",
      "            'start_time': None,\n",
      "            'succeeded': None}}\n"
     ]
    }
   ],
   "source": [
    "from k8scontroller.kubernetes_job import KubeWorker\n",
    "\n",
    "local_root=\"./shared_folder\"\n",
    "kube_worker = KubeWorker(local_root=local_root)\n",
    "api_response = kube_worker.kube_create_job(container_image=\"busybox\",\n",
    "                                          command=[\"/bin/sh\", \"-c\", \"while :; do echo 'IM HERE'; sleep 1; done\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kube_test_credentials() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7f16ae344915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mKubeWorker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkube_test_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mKubeWorker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkube_test_credentials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting cleaning\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mKubeWorker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkube_cleanup_finished_jobs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jobs were Cleaned\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: kube_test_credentials() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "KubeWorker.kube_test_credentials()\n",
    "KubeWorker.kube_test_credentials()\n",
    "print(\"Starting cleaning\")\n",
    "KubeWorker.kube_cleanup_finished_jobs()\n",
    "print(\"Jobs were Cleaned\")\n",
    "KubeWorker.kube_delete_empty_pods()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import Optimizer\n",
    "from skopt.learning import GaussianProcessRegressor\n",
    "from skopt.learning.gaussian_process.kernels import RBF, ConstantKernel, Product\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from skopt import gp_minimize\n",
    "from time import sleep\n",
    "import docker\n",
    "import random\n",
    "import os\n",
    "import string\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# первые n_initial_points модель не обучается\n",
    "n_initial_points = 5\n",
    "\n",
    "# число итераций цикла\n",
    "n_calls = 3\n",
    "\n",
    "# оптимизация на кубе [low_constraint, high_constraint]^dim\n",
    "low_constraint, high_constraint = 2., 301.\n",
    "dim = 1\n",
    "\n",
    "# столько контейнеров вызываются для параллельной работы\n",
    "batch_size = 2\n",
    "\n",
    "# директория на сервере, хранит директории, которые будут монтироваться в контейнеры\n",
    "folder_local = '/home/matyushinleonid/lhcb_ecal/feb_meeting/folder_local'\n",
    "folder_local = '/home/igor/LAMBDA/lhcb_repo'\n",
    "ptint(\"Ваш путь до директории с данными {} \".format(folder_local))\n",
    "\n",
    "# директория для файлов input и output внутри контейнера\n",
    "folder_container = '/home/nb_user/logs'\n",
    "\n",
    "# python-клиент докера\n",
    "client = docker.from_env()\n",
    "\n",
    "# имя образа\n",
    "image = \"calorbuild\"\n",
    "\n",
    "# имена директорий, каждая соответствует своей копии образа\n",
    "worker_names = ['first_worker', 'second_worker']\n",
    "\n",
    "###\n",
    "first_loop_legal_upper_bounds = [i for i in range(3, 301, 3)]\n",
    "#second_loop_legal_upper_bounds = [i // 3 * 4 for i in first_loop_legal_upper_bounds]\n",
    "#space_size = len(first_loop_legal_upper_bounds)\n",
    "#total_amount_of_inner_part = [first_loop_legal_upper_bounds[i] * second_loop_legal_upper_bounds[i] \\\n",
    "#                              for i in range(space_size)]\n",
    "\n",
    "def crop_number(n):\n",
    "    return min(first_loop_legal_upper_bounds, key=lambda t:abs(t-n))\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = Product(ConstantKernel(1), RBF(1)) + ConstantKernel(1)\n",
    "\n",
    "model = GaussianProcessRegressor(alpha=0, \n",
    "                                 normalize_y=True, \n",
    "                                 noise='gaussian', \n",
    "                                 n_restarts_optimizer=10, \n",
    "                                 kernel=kernel)\n",
    "\n",
    "optimizer = Optimizer([[low_constraint, high_constraint]]*dim,\n",
    "                      model,\n",
    "                      n_initial_points=n_initial_points,\n",
    "                      acq_func='EI',\n",
    "                      acq_optimizer='lbfgs',\n",
    "                      random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_folder(folder_local):\n",
    "    list_dir = os.listdir(folder_local)\n",
    "    for _ in range(3):\n",
    "        new_folder ='{}/{}'.format(folder_local,\n",
    "                                   ''.join(random.choice(string.ascii_uppercase + string.digits) for _ in range(10)))\n",
    "        if new_folder not in list_dir:\n",
    "            os.mkdir(new_folder)\n",
    "            return new_folder\n",
    "    raise Exception(\"Cannot create uniq folder\")   \n",
    "\n",
    "\n",
    "def write_input_file(input_data):\n",
    "    job_folder = get_folder(folder_local)\n",
    "    file_to_write = '{}/input.txt'.format(job_folder)\n",
    "    string_to_write = '\\n'.join(map(str, input_data))\n",
    "    with open(file_to_write, \"w\") as file:\n",
    "        print(string_to_write,\n",
    "              file=file)\n",
    "    return job_folder\n",
    "\n",
    "def new_point(x):\n",
    "    croped_x = min(first_loop_legal_upper_bounds, key=lambda t:abs(t-x))\n",
    "    return (croped_x, croped_x // 3 * 4) \n",
    "\n",
    "def create_job(job_folder, **kwargs):\n",
    "    client.containers.run(privileged=True,\n",
    "                          remove=False,\n",
    "                          detach=False,\n",
    "                          hostname='dev',\n",
    "                          tty=True,\n",
    "                          stdin_open=True,\n",
    "                          volumes={job_folder: {'bind': folder_container,\n",
    "                                                     'mode': 'rw'}},\n",
    "                          **kwargs)\n",
    "    \n",
    "\n",
    "def read_output_file(job_folder):\n",
    "    file_to_read = '{}/output.txt'.format(job_folder)\n",
    "    with open(file_to_read, 'r') as myfile:\n",
    "        data = myfile.read()\n",
    "    return float(data)\n",
    "\n",
    "def get_price(params, lamb=1):\n",
    "    param1 = crop_number(params[0])\n",
    "    param2 = param1 // 3 * 4\n",
    "    return lamb * param1 * param2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Queue, Pool, Manager\n",
    "import traceback\n",
    "import logging\n",
    "\n",
    "def test_worker(q_in, q_out):\n",
    "    while True:         \n",
    "        try:\n",
    "            data = q_in.get()            \n",
    "            in_dir = write_input_file(data)\n",
    "            logging.info('Start Job {}'.format(in_dir))\n",
    "            create_job(in_dir, \n",
    "                       image='busybox', \n",
    "                       command=\"/bin/sh -c 'head -1 input.txt > output.txt'\",\n",
    "                       working_dir='/home/nb_user/logs')  \n",
    "            result = read_output_file(in_dir)\n",
    "            q_out.put(( data, result ))   \n",
    "        except:\n",
    "            logging.error(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            logging.error(traceback.format_exc())\n",
    "            raise\n",
    "        logging.info('Job {} is done'.format(in_dir))\n",
    "    return   \n",
    "\n",
    "def worker(q_in, q_out):\n",
    "    while True:         \n",
    "        try:\n",
    "            data = q_in.get()            \n",
    "            in_dir = write_input_file(data)\n",
    "            logging.info('Start Job {}'.format(in_dir))\n",
    "            create_job(in_dir, image='calorbuild')   \n",
    "            result = read_output_file(in_dir)\n",
    "            q_out.put(( data, result ))   \n",
    "        except:\n",
    "            logging.error(\"Unexpected error:\", sys.exc_info()[0])\n",
    "            logging.error(traceback.format_exc())\n",
    "            raise\n",
    "        logging.info('Job {} is done'.format(in_dir))\n",
    "    return   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(optimizer, worker, num_workers, n_calls):\n",
    "    pool = Pool(num_workers) \n",
    "    m = Manager()\n",
    "    q_in = m.Queue()\n",
    "    q_out = m.Queue()\n",
    "    pool.starmap_async(worker, [(q_in, q_out)]*num_workers)\n",
    "\n",
    "    X = optimizer.ask(n_points=num_workers)\n",
    "    for i in range(num_workers):\n",
    "        point = new_point(X[i][0])\n",
    "        q_in.put(point)\n",
    "\n",
    "    for _ in tqdm(range(n_calls-num_workers)): \n",
    "        x, y = q_out.get()\n",
    "        optimizer.tell([x[0]], y) \n",
    "        point = new_point(optimizer.ask()[0])\n",
    "        q_in.put(point)\n",
    "\n",
    "    for _ in range(num_workers):\n",
    "        x, y  = q_out.get()\n",
    "        optimizer.tell([x[0]], y)      \n",
    "\n",
    "    pool.terminate()\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "optimizer = Optimizer([[low_constraint, high_constraint]]*dim,\n",
    "                      model,\n",
    "                      n_initial_points=n_initial_points,\n",
    "                      acq_func='EI',\n",
    "                      acq_optimizer='lbfgs',\n",
    "                      random_state=None)\n",
    "\n",
    "\n",
    "optimizer = optimize(optimizer, worker, 1, 1)\n",
    "print(optimizer.Xi, optimizer.yi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
